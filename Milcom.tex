\documentclass[10pt,twocolumn,conference]{IEEEtran}
%\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
%\usepackage{amsthm, amssymb}
%\usepackage{enumerate}
%\usepackage{fullpage}
%\usepackage{soul}
\usepackage[table]{xcolor}
%\usepackage{float}
%\usepackage{comment}
%\usepackage{listings}
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
\definecolor{Gray}{gray}{0.85}
%\usepackage{fancybox}
%\usepackage{framed}
%\usepackage{mathrsfs}
%\usepackage{url}
%\usepackage{paralist}
%\usepackage{etoolbox}

%\usepackage[font=small,labelfont=bf]{caption}

%\hypersetup{breaklinks=true}
%\urlstyle{same}
%-----------------------------------------------------------------
%\let\labelindent\relax %% Fixes labelindent error in IEETran Class
\usepackage{enumitem}
%\setlist[enumerate]{leftmargin = 9pt}
%\setlist[itemize]{leftmargin = 8pt}
%-----------------------------------------------------------------
\usepackage{balance}
\graphicspath{{Pictures/}}

\begin{document}
    
\title{Data Mining Academic Emails to Model Employee Behaviors and Analyze Organizational Structure}
\author{\IEEEauthorblockN{Kayla M. Straub, Joseph M. Ernst, William C. Headley, Robert W. McGwier}
  \IEEEauthorblockA{Hume Center for National Security and Technology,\\
    Virginia Tech, Blacksburg, VA 24060, USA \\
    Email: \{kstraub, jmernst, cheadley, rwmcgwi\}@vt.edu}
} 
\maketitle

\begin{abstract}
Email correspondence has become the predominant method of communication for businesses.
If not for the inherent privacy concerns, this electronically searchable data could be used to better understand how employees interact.
After the Enron dataset was released, researchers were able to provide great insight into employee behaviors based on the available data despite the many challenges with that dataset.
The work in this paper demonstrates the application of a suite of methods applied to an appropriately anonymized email dataset created from volunteers' email metadata.
This new dataset, from an internal email server, is used to validate feature extraction and machine learning algorithms in order to generate insight into the interactions within the center.
Based solely on email metadata, a random forest approach models behavior patterns and predicts employee job titles with $96\%$ accuracy.
The result represents classifier performance not only on participants in the study but also on other members of the center who were connected to participants through email.
Furthermore, the data revealed relationships not present in the center's formal operating structure.
The result is an organic organizational chart, which contains a fuller understanding of the center's internal structure than can be found in the official organizational chart.
\end{abstract}

\section{Introduction}
A reorganization of a business can be very costly and has great effects once implemented, either for better or for worse.
While this official hierarchy is important, there is an equally important organic structure within any business, which may or may not be reflected in the official organizational chart.
Understanding this unofficial structure is important, but due to its informal nature, it can be difficult to determine.
One massive source of electronically searchable information that can be used to better understand this hidden structure is the business's emails.
Applications of this research are not limited only to corporate operations.
These methods could be applied to any communications system to perform organizational analysis, anomalous behavior detection, or leadership identification.
In a military context, this work shows the importance of protecting this metadata from adversaries who could use it to uncover information about an organization that they could use to find vulnerabilities.

The study presented in this paper collected an appropriately anonymized email metadata dataset to demonstrate how this metadata could be used to determine an organization's underlying organic structure.
It is proposed that this organic chart contains valuable information not present in the official organizational chart.
The study uses email metadata from $36$ voluntary participants.
This metadata is used not only to analyze the voluntary participants, but also to what extent the non-participant members of the organization can be characterized.

The $114$ features used in this study can be grouped into two common areas in email analytics: traffic-based and social-based.
Using random forests, these features are used to predict each employee's job title.
A comparison is drawn between relationships displayed in the data and those depicted in the formal organizational chart.  

This paper continues by discussing the related works in Section~\ref{Related Works}.
Section~\ref{Data Collection} presents the process of data collection and some statistics of the dataset.
The features extracted from the data are described in Section~\ref{Features}, and the methods investigated using these features are covered in Section~\ref{Analysis}.
The results of the analysis are presented in Section~\ref{Results}.
Section~\ref{Conclusions} concludes the paper and presents opportunities for future work.  

\section{Related Works} \label{Related Works}

Email is a pervasive medium for communication in modern society\textemdash{}particularly in the workplace.
In 2015 there were over $2.6$ billion email users~\cite{radicati_emails_2015}.
Corporate email alone accounts for $54.7\%$ of worldwide email traffic, and the average business email user sends and receives a total of $112$ emails per day.
Retention of large email archives has become common practice as computer memory technology improves and becomes increasingly affordable.
This is a considerable amount of untapped information that could be leveraged to characterize employees within an organization.

Since the Enron email dataset was released in 2004 \cite{klimt2004introducing}, it has been extensively researched on topics including spam classification~\cite{martin2005analyzing}; email categorization \cite{he2014novel}; and recipient prediction \cite{sofershtein2015predicting}.
However, there are known flaws and discrepancies with even the most recent versions of this dataset\textemdash{}ranging from misspelled email addresses~\cite{nordbo2014data} to duplicate emails~\cite{waterman2014big}.

The existing literature on analyzing social email behavior is mainly divided into two categories: traffic-based and social-based~\cite{tang2014email}.
Traffic-based methods calculate statistics based only on email patterns.
Social-based methods represent the email communications as a social graph and then extract information from this model about the inherent relationships.
A third type of feature that has been studied utilizes email text.
The work by Gilbert~\cite{gilbert2012phrases} showed that the wording used in an email could be used to make inferences about the corporate hierarchy.
However, email text contains sensitive information and is often unavailable for a general email study.
Therefore, features based on email text are not considered in this work.

By using features extracted from email metadata alone, previous work has been able to cluster levels of management at Enron~\cite{yelupula2008social}.
Other metadata features such as the presence of different email attachment types and the length of emails have been shown to successfully categorize email behavior~\cite{martin2005analyzing}.

For social-based features, relational ties can be modeled as a graph where nodes represent people and edges represent email interactions.
This is a useful model because many statistics can be calculated from a graphical layout~\cite{wasserman1994social}.
A common feature used in social network analysis is betweenness centrality, which comes in several different flavors first developed by Freeman~\cite{freeman1977set}.
Betweenness centrality is a measure of how many shortest paths in a graph travel over each node.
In a graph with edge weights, a shortest path is a route from one node to another that has the minimum edge weight sum.
Note that two or more equivalent shortest paths can exist for a pair of nodes.
A node with high betweenness centrality in a social graph has been shown to represent a high degree of influence on other nodes.

Tyler et al.~\cite{tyler2005mail} used a betweenness centrality algorithm to determine community structures within an organization.
Other successful metrics were used by Wilson and Banzhaf~\cite{wilson2009discovery} to detect the most important email users within a corporate network.
The features used instead were: degree, the number of edges connected to a node; density, the ratio of actual edges to the number of possible edges; and proximity prestige, the ratio of nodes that can reach a node $i$ to the average distance from those nodes to $i$.

Instead of considering exclusively traffic-based or social-based analytics, these features can be used jointly.
The only example of this approach combined features such as number of emails, response time, cliques, and degree centrality into a ``Social Score'', which was used to rank Enron employees~\cite{rowe2007automated}.  
However, this work did not report any quantifiable results.
The aim of this paper is to utilize both types of features in order to produce a measurable comparison between institution's organic chart and its official organizational chart.

\section{Data Collection} \label{Data Collection}

Over the past decade, the Enron dataset has been widely used to study email behaviors because it is one of the only datasets available comprised of real-world corporate emails.
Due to difficulties with the Enron dataset, as described in Section~\ref{Related Works}, this study uses a new dataset generated from volunteers in one of the university's centers.

In consideration of the inherent privacy concerns, researchers worked with the Internal Review Board (IRB) to approve a dataset which maintains participants' privacy.
This dataset is meant to be representative of metadata that any company could use without divesting employees of their email privacy.
Special care was taken to protect the privacy of those involved in the study.
During the collection process, all subject and body text was hashed using MD5, and all email metadata was stored in a secure database using scripts without any researchers observing any email text.
Any identifying information has been omitted from this publication.
The following is the metadata provided from each email:
\begin{itemize}
\item Destination and source email address
\item Email time stamp
\item Subject prefix (e.g., Re:, Fwd:)
\item Hash of subject after removing prefix
\item Hash of body text
\item Length of subject in characters
\item Length of body text in characters
\item Number of attachments
\end{itemize}

Table~\ref{tab:db_stats} compares statistics between this internal dataset and the Enron corpus.
This internal database is more modern, contains more emails, and covers a longer time period, but involves fewer people than were used to construct the Enron dataset.
While the study collected email data from only $36$ volunteers, the email metadata from these volunteers identified $38$ additional employees of the center.
These peripheral employees were included in the study when ground truth for their job was available and when the dataset contained sufficient email metadata records (defined as at least $100$ total emails).
Five of the $36$ direct participants were very new employees to the center, and are not considered in the classification analysis due to lack of sufficient email data.
The email records provided by these employees were still included to help characterize other employees.
Therefore, for all analyses in Section~\ref{Analysis}, $31$ primary participants and $38$ peripheral employees, for a total of $69$ people, were classified.



\begin{table}[t]
\centering
\caption{A comparison between the internal dataset and the Enron email corpus.}
\label{tab:db_stats}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrr@{}}
\toprule
                   & Center                   & Enron         \\ \midrule
Time               & Nov. 2012 - Nov. 2015     & Jan. 2000 - Sept. 2002 \\
Distinct Addresses & $32\,118$                & $75\,406$        \\
Participants       & $36$                     & $158$           \\
Distinct Emails    & $585\,096$               & $252\,759$       \\ \bottomrule
\end{tabular}
}
\end{table}


The center divides its employees into six main areas: directors, graduate students, operations, outreach, project management (PM), and research.
Each person in the study was labeled with his or her job title.
One challenge of working with this dataset is that the distribution of these job titles is far from uniform.
Approximately half of the participants are graduate students, and there are only two outreach personnel included in the study.
Fig.~\ref{fig:db_bar} compares the distribution of job titles to the average number of emails per person per class.
Even though graduate students are by far the largest class, they send the fewest emails per person out of any class.
The directors exhibit opposite behavior: there are only eight directors in the center, but collectively their emails make up almost $50\%$ of the database.

\begin{figure}[t]
	\centering
	\includegraphics[width=\columnwidth,trim={1mm 0mm 1mm 0mm},clip]{DatasetStatsBar_BW}
	\caption{Representation of each class in the dataset with respect to average emails per person and number of people.  Both distributions are very nonuniform, which poses a challenge to the classification algorithm.}
	\label{fig:db_bar}
\end{figure}


\section{Features} \label{Features}
The study includes $114$ features that were extracted from the email data: $84$ traffic-based and $30$ social-based.
The traffic-based features focus on the amount and types of emails each employee sends and receives.
The social features aim to quantify the relationships and social roles within the organization.
In the following sections, all features from each of the two categories are described. 
All of these statistics are used to characterize each employee of the center and serve as the inputs to the machine learning algorithm.

\subsection{Traffic-Based Features}
Traffic-based features include total number of emails, total sent, and total received.
Other features are based on whether recipients were the primary recipient of the email or were copied on the email.
The number of emails sent and received as replies or forwards were used.
Features also included the number of unique email address connections and the number of unique email subjects, sent and received.
The average number of recipients on emails sent and received for each participant were calculated.
It was hypothesized that staff members had more external communications than graduate students.
External communications are defined as emails sent and received from entities not affiliated with the center.
To test this, the number of emails sent and received from within the center and the university were calculated.  

Other useful information collected from emails included the timestamp, character counts of the subject and body, and the presence of any attachments.
Utilizing the timestamp information, the total number of emails sent and received after standard working hours were used as metrics.
The number of emails sent and received after hours specifically between center employees was also recorded.
For this purpose, after hours was defined as between 6 p.m. and 7 a.m. EST on weekdays or anytime on weekends.
The mean and variance of the number of characters in the subject and body were calculated.
These metrics were also broken down between emails sent and received.
The number of attachments sent and received were computed as well as the average number of attachments sent and received per email.
Digitally signing an email or encrypting an email are both recognized as types of attachments.
Additional features were calculated from the total number of signed or encrypted emails sent and received as well as unique email addresses and subjects with signed or encrypted emails.

The features above generally involved raw email counts.
To normalize some of the features, metrics were also calculated as a percentage.
Examples include the percentage of emails that were sent after hours and the percentage of all received emails with unique subjects out of all received emails.

\subsection{Social Network Features}
In addition to tracking metadata statistics, features are also derived from modeling the emails as a social network.
A social network is composed of nodes that represent people, and edges that represent the emails between people.  For this analysis, two different graphs were generated.
In the full graph, an edge exists between any two individuals that exchanged at least one email.
A second graph only produces an edge between two nodes if at least 10 emails were exchanged, in order to filter out emails pertaining to isolated events.
A representation of the full graph is shown as an adjacency matrix in Fig.~\ref{fig:adj_matrix}.
Each of the two axes represent the employees of the center; the x-axis represents the sender and the y-axis represents the recipient.
The color at each coordinate indicates the volume of emails sent between the two employees.
The diagonal represents when a person emails or copies themselves.
Some employees never exchanged any emails, while others exchanged several thousand.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth,trim={0mm 0mm 0mm 0mm},clip]{GrayBiggerFont}
    \caption{The adjacency matrix representing the social connections of the center.  There are groups within the center that exchanged thousands of emails as well as groups who never exchanged a single email.}
    \label{fig:adj_matrix}
\end{figure}

With this representation, statistics can be calculated about the people in the graph.
The degree of each node was calculated for both the partial and full graph.
The degree of a node $i$ is the number of other nodes connected to node $i$, and these connected nodes are called neighbors of $i$.
The average neighbor degree of each node was also computed as a feature.
For a node $i$, this metric averages the degree of each node in the neighborhood of $i$, that is all nodes connected to $i$.
The distances between nodes were also used to generate some features.
The average shortest path metric calculates the length of the shortest paths between node $i$ and all other nodes in the graph $G$, and it returns the average of these path lengths.
The maximum shortest path length, or eccentricity, was used as a feature in the learning algorithm.  

Some of the social features were based on existing graph theory concepts and algorithms.
If a subgraph of a graph $G$ is maximally connected, that is all nodes are connected directly to each other, then this is called a clique.
The number of cliques to which a node belongs was used as a feature.
The hubs and authorities of each node in both graphs were calculated.
The terms hubs and authorities come from the Hyperlink-Induced Topic Search (HITS algorithm) developed by~\cite{kleinberg1999hubs}.
This algorithm was originally designed to rate web pages, but has since been applied to social networks.
A node's authority is just that\textemdash{}a measure of its importance over other nodes.
A node's hub score is a measure of how well-connected it is to other nodes.

Another algorithm used to generate features was the pagerank algorithm, developed by Google~\cite{page1999pagerank} also to rank web pages for search results.
The assumption is that the most important web pages will be linked to frequently by other pages.
Therefore, the ranking is determined by estimating the quality and quantity of links to a node.
The square clustering coefficient for each node was used as a feature.
Say there exists a node $i$ with neighbors $j$ and $k$.
This metric, developed by~\cite{lind2005cycles}, measures the probability that $j$ and $k$ are also neighbors to a fourth node, $l$.
The higher the clustering coefficient, the more connected the node is within its neighborhood.
The triangle clustering coefficient was also used as a metric.
This value, developed by~\cite{saramaki2007generalizations}, is the same as the square clustering coefficient but instead determines the probability of connected triangles involving each node.

The majority of the social-based features were centrality measures.
This includes closeness centrality, betweenness centrality, degree centrality~\cite{borgatti2011analyzing}, current flow closeness centrality, current flow betweenness centrality~\cite{brandes2005centrality}, communicability centrality, communicability betweenness centrality~\cite{estrada2008communicability}, and load centrality~\cite{newman2001structure}.

\section{Analysis} \label{Analysis}
Due to the large number of features and relatively low number of participants, a classification method was carefully chosen to avoid overfitting the data.
A random forest classifier was chosen for this study because it is extremely robust to overfitting.
The Java-based software package Weka was used to generate the random forest based on the algorithm described by Breiman~\cite{Breiman2001}.

Random forest training is an ensemble method of machine learning, comprised of many random trees.
A random tree is an algorithm that uses training data to learn a series of rules to divide the data into the various classes.
Each rule is designed such that it will split the data in a way that maximizes the mutual information.
These rules are constructed in a hierarchy that visually resembles a tree.

%An example random tree with depth three is shown in Fig.~\ref{fig:ex_tree}.

\begin{figure}[t]
	\centering
	\includegraphics[width=5cm,height=5cm,keepaspectratio,trim={0mm 2.5mm 0mm 2mm},clip]{RandForest_BW}
	\caption{The random forest method aggregates many random trees via bagging to build a robust classifier.}
	\label{fig:rand_forest}
\end{figure}  


A visualization of the random forest training process is shown in Fig.~\ref{fig:rand_forest}.
Random forests build many random trees with imposed random variations.
Individually, these random trees overfit the data.
To overcome this, random trees are combined through a process of bootstrap aggregating, or bagging to build a much more robust classifier.
The bagging process involves each random tree generating a new training data set by sampling observations from the input training set with replacement.
These subsamples are used to build the random trees.
For this analysis, each tree selects $\frac{2N}{3}$ samples to train the trees where $N$ is the number of people in the overall training set.
Just as the samples were subsampled, so were the features.
Only this subset of features can be used as rules for that tree.
A validation set was used to determine the optimal values for the hyperparameters of the algorithm.
This analysis determined that each forest should contain 750 trees and each tree would use a subsample of 7 random features.

After all the trees are built from the training data, the test data is run through all the random trees in the forest.
Each tree outputs a prediction label for each data point, and the majority vote on each sample is the final predicted label.
This random forest model reduces the variance and increases the accuracy of the model compared to a single random tree.

Random forests can be difficult to interpret because the ensemble method obscures which features are most meaningful.
Since random trees use mutual information to optimize branch splits, mutual information was used as the evaluation criteria to rank the features.
Each attribute is evaluated by measuring the mutual information with respect to the class.
In this model, both the feature value and the class are treated as random variables.
Mutual information represents how well knowledge of the attribute informs prediction of the class.
Mutual information is calculated as follows:
\begin{equation}
I(\text{Class}; \text{Feature}) = H(\text{Class}) - H(\text{Class} | \text{Feature})
\end{equation} \label{eq:info_gained}
\hspace{-\parindent}
where $I(\text{Class}; \text{Feature})$ represents the mutual information between the class and the feature, $H(\text{Class})$ is the entropy of the class variable, and  $H(\text{Class} | \text{Feature})$ represents the conditional entropy of the class given the feature value.  

This mutual information value is then used to rank the importance of each feature.
Table~\ref{tab:ranked_feats} shows the top $20$ features from this analysis and the features' corresponding mutual information.
Highlighted rows represent the features not used previously in email analysis.

\begin{table}[t]
\centering
\caption{Top 20 features ranked by the mutual information.}
\label{tab:ranked_feats}
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lrr@{}}
\toprule
Feature                                      & Type         & Mutual Information\\ \midrule
Partial graph hubs                           & Social        & 0.589  \\
Full graph hubs                              & Social        & 0.554  \\
Number of emails received as forwards        & Traffic      & 0.554  \\
\rowcolor{Gray}
Number of signed emails received             & Traffic      & 0.514  \\
\rowcolor{Gray}
Number of signed emails received with unique subjects & Traffic & 0.514\\ 
Partial graph current flow closeness centrality & Social    & 0.512  \\
Partial graph pagerank                       & Social       & 0.512  \\
Number of emails received as copies          & Traffic      & 0.500  \\
Number of emails received from center employees & Traffic	    & 0.492  \\
Full graph current flow closeness centrality & Social       & 0.492  \\
Full graph pagerank                          & Social       & 0.492  \\
Average number of emails received per day    & Traffic      & 0.489  \\
Partial graph communicability centrality     & Social       & 0.486  \\
\rowcolor{Gray}
Partial graph communicability betweenness centrality & Social & 0.486  \\
Average number of emails per day (sent and received) & Traffic & 0.479    \\
Number of emails sent to center employees      & Traffic	    & 0.476  \\
Partial graph number of cliques              & Social       & 0.470  \\
Percentage of emails received as forwards    & Traffic      & 0.451  \\
Partial graph degree centrality				 & Social		& 0.448  \\
Partial graph average shortest paths         & Social	    & 0.448  \\ \bottomrule \\
\footnotesize Note: Highlighted rows represent features unique to this work.
\end{tabular} 
}   
\end{table} 

\section{Results} \label{Results}
This section first shows the algorithm's ability to correctly classify both the study's volunteers and the additional employees identified from the volunteers' emails.
The second part of the results section assumes perfect labeling of the employees and compares email interactions to the official organizational chart.
The ultimate goal of this research is to determine an organic hierarchy, generated entirely from the email data.

\subsection{Classification Results}\label{ssec:class_results}
Each email is randomly assigned to either the training or testing set with equal probability.
All of the metrics described in Section~\ref{Features} were calculated for both groups separately.
The training data is used as input to the random forest algorithm as described in Section~\ref{Analysis}, and predictions are generated for the test data.
The number of correct and incorrect classifications for each class are shown in Fig.~\ref{fig:result_hist}.
Note that only three predictions were wrong, and all were a result of confusing research staff with graduate students.
It is important to note that two of these misclassifications are peripheral participants.
Therefore, the classification accuracy for the study participants is $96.8\%$, correctly classified inferred employees is $94.7\%$, and the overall accuracy of this method using all features is $95.7\%$.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\columnwidth,trim={1mm 8mm 10mm 0mm},clip]{Classification_confusion_BW}
    \caption{The random forest algorithm was extremely accurate even for very uneven class sizes.  Note that all members of the four smallest classes were labeled perfectly.  There were only three errors out of $69$ employees, two of which for employees who did not provide emails for the study.}
    \label{fig:result_hist}
\end{figure}


\subsection{Hierarchy Analysis}
A combination of the predicted labels from Section~\ref{ssec:class_results} and the email patterns from the data generated the organic hierarchy for the center, shown in Fig.~\ref{fig:org_chart}.
This chart represents only the flow of project information for the center: from directors to project managers to research staff down to graduate students.
Outreach and operations personnel are not actively involved in project work, and are therefore omitted from this chart.
Edges are drawn from each layer to the layer above based on how many emails were sent.
For example, each graduate student has three edges corresponding to the three researchers they emailed most frequently.
The most emailed researcher is the darkest line, the second-most common researcher is more transparent, and the third-most common link is the most transparent.

\begin{figure}[t]
	\centering
	\includegraphics[width=\columnwidth,trim={0mm 1mm 0mm 1mm},clip]{org_chart_with_legend_no_red}
	\caption{Project organizational chart generated from the email data. This analysis could be used as a tool in corporate mergers or restructuring in order to better understand the communication network of an organization.}
	\label{fig:org_chart}
\end{figure}

To generate a measure of how well the email-based organic structure compares to the organizational chart, the relationships in Fig.~\ref{fig:org_chart} and the rest of the email data were compared to the official hierarchy.

Most of the employees at the center are organized under a director and work with a program manager (unless for example they are a director or program manager).
The director and project manager for each applicable employee is predicted from the email metadata.
The accuracy of these predictions are summarized for all classes in Fig.~\ref{fig:project_analysis}.
For each employee, the algorithm predicts the director that that employee communicated with most by email.
Comparing these predictions to the official chart, only $52.63\%$ of the center's employees communicate most frequently with their assigned director.
This result shows a clear disconnect between the official organizational chart and the organic relationships within the center.

To identify each employee's project manager, ground truth is selected to be the project that primarily funds the employee.
Note that employees with job titles of project manager, outreach, and operations have directors, but no equivalent to project manager.
This time, $91.67\%$ of graduate students and researchers communicate most frequently with their primary program manager.
The relationships between employees and project managers appear to be stronger than that with directors.
In the case of project managers, the organic and official hierarchies more closely match.

\begin{figure}[t]
	\centering
	\includegraphics[width=\columnwidth,trim={1mm 5mm 10mm 2mm},clip]{superior_identification_BW}
	\caption{The official director of an employee, from the organizational chart, is often not the director with whom they exchange the most emails.  However, graduate students and researchers often communicate most frequently with their primary project manager.}
	\label{fig:project_analysis}
\end{figure}

\section{Conclusions and Future Work} \label{Conclusions}
This work examines how email metadata can be used to predict an organization's internal structure.
These methods can be applied to other communication systems such as cellular phones, social media, and wireless networks to gain an understanding of the leadership hierarchy.

A contribution of this work is a new dataset, larger than Enron, that was collected from volunteers' emails with particular attention to protect participant privacy.
The new dataset includes accurate labels prepared by researchers with knowledge of the center and its employees.
Features were extracted from this dataset, and used with a random forest algorithm to automatically classify the center's employees.
Random forests are shown to be powerful classifiers by predicting employee job titles with $96\%$ accuracy, even for employees for whom only secondhand data is available from the dataset.

An organic organizational chart was generated from the email data and contrasted with the official corporate hierarchy.
The organic chart showed that emails could be used to predict an employee's primary program manager with $92\%$ accuracy.
This method was less accurate, $52.63\%$, at identifying the director associated with the employee on the official organizational chart.
This work has shown that it is possible to infer important organizational information from using carefully processed email metadata without compromising the privacy of employees.
Future work will attempt to further explore the center's organic hierarchy through this data as well as to apply these algorithms to other datasets to determine the general applicability of the results.

\balance

\Urlmuskip=0mu plus 1mu\relax
\bibliographystyle{IEEEtran}
\bibliography{bib}


\end{document}
